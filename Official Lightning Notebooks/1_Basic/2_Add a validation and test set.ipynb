{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0ec73d",
   "metadata": {},
   "source": [
    "# Validate and test a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356465b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lightning --quiet --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8d216",
   "metadata": {},
   "source": [
    "## Add a test loop\n",
    "To make sure a model can generalize to an unseen dataset (ie: to publish a paper or in a production environment) a dataset is normally split into two parts, the train split and the test split.\n",
    "\n",
    "The test set is NOT used during training, it is ONLY used once the model has been trained to see how the model will do in the real-world.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45299e66",
   "metadata": {},
   "source": [
    "### Find the train and test splits\n",
    "Datasets come with two splits. Refer to the dataset documentation to find the train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d344dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3b9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sets\n",
    "transform = transforms.ToTensor()\n",
    "train_set = datasets.MNIST(root=\"MNIST\", download=True, train=True, transform=transform)\n",
    "test_set = datasets.MNIST(root=\"MNIST\", download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0bc50",
   "metadata": {},
   "source": [
    "### Define the test loop\n",
    "To add a test loop, implement the `test_step` method of the LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28589e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8293a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat.view(x.size(0), 1, 28, 28)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, _ = batch\n",
    "        x_hat = self(x)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is test loop\n",
    "        x, _ = batch\n",
    "        x_hat = self(x)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5650d",
   "metadata": {},
   "source": [
    "### Train with the test loop\n",
    "Once the model has finished training, call `.test()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a17867b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train\n",
      "1 | decoder | Decoder | 51.2 K | train\n",
      "--------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train\n",
      "1 | decoder | Decoder | 51.2 K | train\n",
      "--------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56ff51ebb4c454bb7a518fcdf92b863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "autoencoder = LitAutoEncoder(Encoder(), Decoder())\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(max_epochs=1, max_steps=1000)\n",
    "trainer.fit(model=autoencoder, train_dataloaders=DataLoader(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d09d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1c2acc48e947cf88676e29ab7ae55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\">        Test metric        </span>‚îÉ<span style=\"font-weight: bold\">       DataLoader 0        </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">    0.05340554937720299    </span>‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.05340554937720299   \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.05340554937720299}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model\n",
    "trainer.test(autoencoder, dataloaders=DataLoader(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d012ca8",
   "metadata": {},
   "source": [
    "## Add a validation loop\n",
    "During training, it's common practice to use a small portion of the train split to determine when the model has finished training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb38d3",
   "metadata": {},
   "source": [
    "### Split the training data\n",
    "As a rule of thumb, we use 20% of the training set as the validation set. This number varies from dataset to dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c05f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 20% of training data for validation\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = data.random_split(train_set, [train_set_size, valid_set_size], generator=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3895ce",
   "metadata": {},
   "source": [
    "### Define the validation loop\n",
    "To add a validation loop, implement the `validation_step` method of the LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f674ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat.view(x.size(0), 1, 28, 28)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, _ = batch\n",
    "        x_hat = self(x)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, _ = batch\n",
    "        x_hat = self(x)\n",
    "        val_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is test loop\n",
    "        x, _ = batch\n",
    "        x_hat = self(x)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580c71f",
   "metadata": {},
   "source": [
    "### Train with the validation loop\n",
    "To run the validation loop, pass in the validation set to `.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd5fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train\n",
      "1 | decoder | Decoder | 51.2 K | train\n",
      "--------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train\n",
      "1 | decoder | Decoder | 51.2 K | train\n",
      "--------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1694fa55b78f4341839f701a34703b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2733adbb64ba441dadc3618cc105bf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_set)\n",
    "valid_loader = DataLoader(valid_set)\n",
    "model = LitAutoEncoder(Encoder(), Decoder())\n",
    "\n",
    "# train with both splits\n",
    "trainer = L.Trainer(max_epochs=1, max_steps=1000)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414dae5b",
   "metadata": {},
   "source": [
    "# Saving and loading checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d55b9f",
   "metadata": {},
   "source": [
    "## What is a checkpoint?\n",
    "When a model is training, the performance changes as it continues to see more data. It is a best practice to save the state of a model throughout the training process. This gives you a version of the model, a checkpoint, at each key point during the development of the model. Once training has completed, use the checkpoint that corresponds to the best performance you found during the training process.\n",
    "\n",
    "Checkpoints also enable your training to resume from where it was in case the training process is interrupted.\n",
    "\n",
    "PyTorch Lightning checkpoints are fully usable in plain PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4fbc82",
   "metadata": {},
   "source": [
    "## Contents of a checkpoint\n",
    "A Lightning checkpoint contains a dump of the model's entire internal state. Unlike plain PyTorch, Lightning saves everything you need to restore a model even in the most complex distributed training environments.\n",
    "\n",
    "Inside a Lightning checkpoint you'll find:\n",
    "\n",
    "- 16-bit scaling factor (if using 16-bit precision training)\n",
    "\n",
    "- Current epoch\n",
    "\n",
    "- Global step\n",
    "\n",
    "- LightningModule's state_dict\n",
    "\n",
    "- State of all optimizers\n",
    "\n",
    "- State of all learning rate schedulers\n",
    "\n",
    "- State of all callbacks (for stateful callbacks)\n",
    "\n",
    "- State of datamodule (for stateful datamodules)\n",
    "\n",
    "- The hyperparameters (init arguments) with which the model was created\n",
    "\n",
    "- The hyperparameters (init arguments) with which the datamodule was created\n",
    "\n",
    "- State of Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da21ae",
   "metadata": {},
   "source": [
    "## Save a checkpoint\n",
    "Lightning automatically saves a checkpoint for you in your current working directory, with the state of your last training epoch. This makes sure you can resume training in case it was interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "941169f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train\n",
      "1 | decoder | Decoder | 51.2 K | train\n",
      "--------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train\n",
      "1 | decoder | Decoder | 51.2 K | train\n",
      "--------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8af7b4af72f489594c60002b1b2687e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf054672bc14b52a68b1422aff8871f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624b5b12a7e64100852ac24aa8e1ab68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\">        Test metric        </span>‚îÉ<span style=\"font-weight: bold\">       DataLoader 0        </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">   0.049939341843128204    </span>‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m  0.049939341843128204   \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.049939341843128204}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=1, default_root_dir=\"./lightning_logs\", max_steps=1000)\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "trainer.test(model, dataloaders=DataLoader(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ce2bd",
   "metadata": {},
   "source": [
    "## LightningModule from checkpoint\n",
    "To load a LightningModule along with its weights and hyperparameters use the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "022e12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder.load_from_checkpoint(\"lightning_logs/lightning_logs/version_1/checkpoints/epoch=0-step=48000.ckpt\", encoder=Encoder(), decoder=Decoder(), map_location=\"cpu\")\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "# predict with the model\n",
    "sample_x = torch.rand(1, 28, 28)\n",
    "y_hat = model(sample_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "815a9546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7b7199e4c110>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(y_hat[0][0].detach().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442e966",
   "metadata": {},
   "source": [
    "### Save hyperparameters\n",
    "The LightningModule allows you to automatically save all the hyperparameters passed to init simply by calling `self.save_hyperparameters()`.\n",
    "\n",
    "```python\n",
    "class MyLightningModule(LightningModule):\n",
    "    def __init__(self, learning_rate, another_parameter, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "```\n",
    "\n",
    "The hyperparameters are saved to the \"hyper_parameters\" key in the checkpoint\n",
    "\n",
    "```python\n",
    "checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "print(checkpoint[\"hyper_parameters\"])\n",
    "# {\"learning_rate\": the_value, \"another_parameter\": the_other_value}\n",
    "```\n",
    "\n",
    "The LightningModule also has access to the Hyperparameters\n",
    "\n",
    "```python\n",
    "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
    "print(model.hparams.learning_rate)\n",
    "```\n",
    "\n",
    "### Save hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83c7ac",
   "metadata": {},
   "source": [
    "## Resume training state\n",
    "If you don't just want to load weights, but instead restore the full training, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0ed2465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: Restoring states from the checkpoint path at lightning_logs/lightning_logs/version_1/checkpoints/epoch=0-step=48000.ckpt\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Restoring states from the checkpoint path at lightning_logs/lightning_logs/version_1/checkpoints/epoch=0-step=48000.ckpt\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:445: The dirpath has changed from 'lightning_logs/lightning_logs/version_1/checkpoints' to 'lightning_logs/lightning_logs/version_8/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train\n",
      "1 | decoder | Decoder | 51.2 K | train\n",
      "--------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K | train\n",
      "1 | decoder | Decoder | 51.2 K | train\n",
      "--------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO: Restored all states from the checkpoint at lightning_logs/lightning_logs/version_1/checkpoints/epoch=0-step=48000.ckpt\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Restored all states from the checkpoint at lightning_logs/lightning_logs/version_1/checkpoints/epoch=0-step=48000.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0543355cfae346a59598773b330ec2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "model = LitAutoEncoder(Encoder(), Decoder())\n",
    "trainer = L.Trainer(max_epochs=1, default_root_dir=\"lightning_logs\")\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=valid_loader, ckpt_path=\"lightning_logs/lightning_logs/version_1/checkpoints/epoch=0-step=48000.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e54fb",
   "metadata": {},
   "source": [
    "## Disable checkpointing\n",
    "You can disable checkpointing by passing:\n",
    "\n",
    "```python\n",
    "trainer = Trainer(enable_checkpointing=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c4cf5f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
